{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For Pytorch import in general\n",
    "import torch\n",
    "\n",
    "#Required for the Network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Required for the Dataset import and processing\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LeNet-5 Architecture](https://www.researchgate.net/profile/Sheraz_Khan8/publication/321586653/figure/fig4/AS:568546847014912@1512563539828/The-LeNet-5-Architecture-a-convolutional-neural-network.png)\n",
    "### The LeNet-5 Network(Code)\n",
    "\n",
    "The Layer name given alongside in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    #Constructor Method\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5) # for C1\n",
    "        self.Conv2=nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5) #for C3\n",
    "        \n",
    "        self.Linear1=nn.Linear(in_features=16*5*5,out_features=120) #for C5\n",
    "        self.Linear2=nn.Linear(in_features=120,out_features=84) #for F6\n",
    "        self.Output=nn.Linear(in_features=84,out_features=10) #for output layer\n",
    "        \n",
    "        \n",
    "    #__The Forward Pass Method\n",
    "    def forward(self,t):\n",
    "        \n",
    "        #__[1] Convolution and Pooling Layer \n",
    "        t=self.Conv1(t)\n",
    "        t=F.tanh(t)\n",
    "        t=F.avg_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        #__[2] Convolution and Pooling Layer\n",
    "        t=self.Conv2(t)\n",
    "        t=F.tanh(t)\n",
    "        t=F.avg_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        #__[3] The First Linear Layer \n",
    "        t=t.reshape(-1,16*5*5)\n",
    "        t=self.Linear1(t)\n",
    "        t=F.tanh(t)\n",
    "        \n",
    "        #__[4] The Second Linear Layer\n",
    "        t=self.Linear2(t)\n",
    "        t=F.tanh(t)\n",
    "        \n",
    "        #__[5] The Output Linear layer\n",
    "        t=self.Output(t)\n",
    "        t=F.softmax(t, dim=1)\n",
    "        \n",
    "        #return the resuling Tensor\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#The Grayscale converts the RGB image to gray scale\n",
    "transformation=transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.ToTensor()])\n",
    "\n",
    "train_set=datasets.CIFAR10(r'C:\\Users\\Soumyajit Sarkar\\Desktop\\Personal Projects\\CIFAR10',train=True,download=True,\n",
    "                           transform=transformation)\n",
    "\n",
    "test_set=datasets.CIFAR10(r'C:\\Users\\Soumyajit Sarkar\\Desktop\\Personal Projects\\CIFAR10',train=False,download=True,\n",
    "                          transform=transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders for Train and Test (Batch Size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=torch.utils.data.DataLoader(train_set,batch_size=250,shuffle=True)\n",
    "test=torch.utils.data.DataLoader(test_set,batch_size=250,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop ( epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object for the LeNet class\n",
    "network = LeNet()\n",
    "\n",
    "# Object for the SGD class (Stochastic Gradient Descent), which is inside the torch.optim package\n",
    "# network.parameters() has the weights and lr stands for Learning Rate.\n",
    "optimizer = optim.SGD(network.parameters(),lr=0.0001)\n",
    "\n",
    "#List to store total loss and total correct for each epoch\n",
    "tLoss=[]\n",
    "tCorrect=[]\n",
    "\n",
    "# epoch loop\n",
    "for epoch in range(100):\n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "\n",
    "    for batch in train:\n",
    "        #images is a tensor of size 50x1x32x32, 50 because our batch size was of 50.\n",
    "        images,labels=batch\n",
    "    \n",
    "        #Sending the Image tensor to the netwrok\n",
    "        prediction_from_network= network(images)\n",
    "    \n",
    "        #Calculating the loss, using Cross-Entropy loss function\n",
    "        loss=F.cross_entropy(prediction_from_network,labels)\n",
    "    \n",
    "        # Since SGD class has Optim Class as it's Super Class, therefore I can call zero_grad method from optim to \n",
    "        # make all the current gradients count = zero, since pytorch keeps on adding the gradients\n",
    "        optimizer.zero_grad\n",
    "    \n",
    "        #Calculate Gradients for this batch of inputs \n",
    "        loss.backward()\n",
    "    \n",
    "        #Updating the Weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss+=loss\n",
    "        total_correct+=prediction_from_network.argmax(dim=1).eq(labels).sum().item()\n",
    "        \n",
    "    #accuracy=(total_correct/len(train_set))*100\n",
    "    \n",
    "    #print(\"epoch \",epoch,\", The total correct is=\",total_correct,\", the total loss=\",total_loss.item(),\n",
    "    #      \", Accuracy is=\",accuracy)\n",
    "    \n",
    "    tLoss.append(total_loss.item())\n",
    "    tCorrect.append(total_correct)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[((x/len(train_set))*100) for x in tCorrect]\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss change with each epoch\")\n",
    "#plt.plot(t)\n",
    "plt.plot(tLoss)\n",
    "plt.show()\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss for test run = 85.73223114013672\n",
      "Test Accuracy = 31.46\n"
     ]
    }
   ],
   "source": [
    "total_correct_test=0\n",
    "total_loss_test=0\n",
    "\n",
    "for test_batch in test:\n",
    "    image_test,label_test=test_batch\n",
    "    \n",
    "    pred_test=network(image_test)\n",
    "    \n",
    "    loss_test=F.cross_entropy(pred_test,label_test)\n",
    "    \n",
    "    total_correct_test+=pred_test.argmax(dim=1).eq(label_test).sum().item()\n",
    "    \n",
    "    total_loss_test+=loss_test\n",
    "    \n",
    "print(\"Total Loss for test run =\",total_loss_test.item())\n",
    "\n",
    "print(\"Test Accuracy =\",(((total_correct_test)/len(test_set))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
